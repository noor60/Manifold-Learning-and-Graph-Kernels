# -*- coding: utf-8 -*-
"""Graph_SVM_PPI.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nG7YO-Jx3RwPHR5T8OA_cxYWkmsTlG-8
"""



pip install grakel[lovasz]



pip install grakel



from grakel import GraphKernel
from grakel.kernels import ShortestPath
sp_kernel = ShortestPath()

from grakel.kernels import WeisfeilerLehman, VertexHistogram
wl_kernel = WeisfeilerLehman(base_graph_kernel=VertexHistogram)

from grakel import Graph
import csv

def graph_creation(i):
 listt=[]
 with open('/content/graph'+str(i)+'.csv') as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for row in csv_reader:
        listt.append(row)
    
    #//convertngomtp int
    for i in listt:
     index = listt.index(i)
     listt[index] = list(map(int, listt[index]))

 return listt

def node_labels(i):
    dict = {}
    count=0
    with open('/content/'+str(i)+'.csv') as csv_file:
     csv_reader = csv.reader(csv_file, delimiter=',')
    
     for row in csv_reader:
        a = ' '.join(map(str, row))
        dict[count]=a
        count +=1
    
    return dict

Y= ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']

for i in range(1,87):
    adj=graph_creation(i);
    label=node_labels(i)
    label[0]='0' 
    
    
    G = Graph(initialization_object=adj, node_labels = label)
    GL.append(G)
    k=sp_kernel.fit_transform([G])

sp_kernel = ShortestPath(normalize=True)
countk = 0

GL=[]
for i in range(1,87):
    adj=graph_creation(i);
    label=node_labels(i)
    label[0]='0' 
    G = Graph(initialization_object=adj, node_labels = label)
    GL.append(G)
    k=sp_kernel.fit_transform([G])

from grakel.kernels import WeisfeilerLehman, VertexHistogram
wl_kernel = WeisfeilerLehman(n_iter=5, normalize=True, base_graph_kernel=VertexHistogram)

from sklearn.model_selection import train_test_split
G_train, G_test, y_train, y_test = train_test_split(GL, Y, test_size=0.3, random_state=42)

K_train = sp_kernel.fit_transform(G_train)

K_test = sp_kernel.transform(G_test)

from sklearn.svm import SVC
clf = SVC(kernel='precomputed')
clf.fit(K_train, y_train)
SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='scale',
    kernel='precomputed', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)

y_pred = clf.predict(K_test)

from sklearn.metrics import accuracy_score
print("%2.2f %%" %(round(accuracy_score(y_test, y_pred)*100)))

from grakel import GraphKernel
from grakel import Graph
import csv

#### weisfeilerlehmen kernal###
from grakel.kernels import WeisfeilerLehman, VertexHistogram
wl_kernel = WeisfeilerLehman(n_iter=5, normalize=True, base_graph_kernel=VertexHistogram)
wl_kernel = WeisfeilerLehman(base_graph_kernel=VertexHistogram)

##### shortest path kernal
from grakel.kernels import ShortestPath
sp_kernel = ShortestPath()
sp_kernel = ShortestPath(normalize=True)


def graph_creation(i):
 listt=[]
 with open('/content/graph'+str(i)+'.csv') as csv_file:
    csv_reader = csv.reader(csv_file, delimiter=',')
    for row in csv_reader:
        listt.append(row)
    
    #//convertngomtp int
    for i in listt:
     index = listt.index(i)
     listt[index] = list(map(int, listt[index]))

 return listt

 def node_labels(i):
    dict = {}
    count=0
    with open('/content/'+str(i)+'.csv') as csv_file:
     csv_reader = csv.reader(csv_file, delimiter=',')
    
     for row in csv_reader:
        a = ' '.join(map(str, row))
        dict[count]=a
        count +=1
    
    return dict

Y= ['1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '1', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2', '2']

countk = 0
GL=[]
for i in range(1,87):
    adj=graph_creation(i);
    label=node_labels(i)
    label[0]='0' 
    G = Graph(initialization_object=adj, node_labels = label)
    GL.append(G)
    k=sp_kernel.fit_transform([G])


from sklearn.model_selection import train_test_split
G_train, G_test, y_train, y_test = train_test_split(GL, Y, test_size=0.3, random_state=42)
K_train = wl_kernel.fit_transform(G_train)
K_test = wl_kernel.transform(G_test)



from sklearn.svm import SVC
clf = SVC(kernel='precomputed')
clf.fit(K_train, y_train)
SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,
    decision_function_shape='ovr', degree=3, gamma='scale',
    kernel='precomputed', max_iter=-1, probability=False, random_state=None,
    shrinking=True, tol=0.001, verbose=False)

y_pred = clf.predict(K_test)
from sklearn.metrics import accuracy_score
print("%2.2f %%" %(round(accuracy_score(y_test, y_pred)*100)))